{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "PdOqyCYSdxKc",
    "outputId": "f537ccbf-6052-4191-811f-780f42d7d8ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "id": "qa3rRZLKeAkA",
    "outputId": "ca4f3a22-86cb-453d-e95b-5666fdc00b8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Nguyet_Projects/Spell_Correction_and_Text_Classify/spell_train\n",
      "27_topic_data.pkl  eval_data.pkl  VNTC_data.pkl\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/Nguyet_Projects/Spell_Correction_and_Text_Classify/spell_train'\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "YLnBffcbkT22",
    "outputId": "9059f478-6c58-4a61-d8a1-9e127f3db6a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61671 60120\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "data = pickle.load(open('VNTC_data.pkl', 'rb'))\n",
    "print(len(data),len(set(i for i in data)))\n",
    "import re\n",
    "alphabet = '^[ _abcdefghijklmnopqrstuvwxyz0123456789áàảãạâấầẩẫậăắằẳẵặóòỏõọôốồổỗộơớờởỡợéèẻẽẹêếềểễệúùủũụưứừửữựíìỉĩịýỳỷỹỵđ!\\\"\\',\\-\\.:;?_\\(\\)]+$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "bJtTEdksaIGR",
    "outputId": "89450a8b-e4e1-4783-87eb-b952e337fdf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148703\n"
     ]
    }
   ],
   "source": [
    "training_data=[]\n",
    "for i in data:\n",
    "  i=i.replace(\"\\n\",\".\")\n",
    "  sentences=i.split(\".\")\n",
    "  for j in sentences:\n",
    "      if len(j.split()) > 2 and re.match(alphabet, j.lower()):\n",
    "          training_data.append(j)\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrPysUyuX2x-"
   },
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "gI8pYWxpKLwg",
    "outputId": "dc005a93-693d-4eca-dae5-18fd90eaf639"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Nếu một doanh nghiệp đưa ra mức lương cao quá hoặc thấp quá so với mặt bằng chung, chúng tôi sẽ phải đặt dấu hỏi và tìm cách trả lời câu hỏi đó bằng các cuộc điều tra riêng của công ty', ' Có thể bằng cách trắc nghiệm hoặc trực tiếp điều tra', ' Tuy nhiên, để có lợi cho mình, chính doanh nghiệp cũng cần đưa ra những thông tin chính xác', 'Gửi tiền vào dễ nhưng rút ra khó', 'Dịch vụ tiết kiệm hỗn hợp của Eximbank là sự phối hợp giữa tiết kiệm có kỳ hạn và không kỳ hạn, cho phép người gửi tiền có thể gửi vào hay rút tiền ra bất cứ lúc nào, có thể chuyển khoản hoặc thanh toán, lãi suất huy động cao hơn lãi suất không kỳ hạn', 'Tuy nhiên, Quyết định 1160 của Ngân hàng Nhà nước ghi rõ khách hàng rút tiền trước hạn phải thông báo trước cho ngân hàng, nếu không thông báo phải nộp một khoản phí bên cạnh việc khoản tiền rút trước hạn chỉ được tính lãi suất không kỳ hạn', ' Một cán bộ của ngân hàng Nhà nước giải thích rằng quy định này nhằm hạn chế việc khách rút tiền trước hạn, gây khó khăn cho các ngân hàng', ' Tuy nhiên, theo một số ngân hàng thương mại, có rất ít các trường hợp khách rút tiền trước hạn', ' Do vậy, hiệu quả của quyết định này chưa thấy đâu, nhưng trước mắt đã gây cho người gửi tiền tâm lý \"gửi tiền vào ngân hàng thì dễ, rút ra thì khó\"']\n"
     ]
    }
   ],
   "source": [
    "print(training_data[-10:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vpc6nD4-d74i"
   },
   "outputs": [],
   "source": [
    "MAXLEN = 40\n",
    "NGRAM = 5\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "Jj4mI7jXOdel",
    "outputId": "0a9b6701-597e-4f41-cc2d-c1b6d2fb41dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-R0-m3KeBWk"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "letters=list(\"abcdefghijklmnopqrstuvwxyzáàảãạâấầẩẫậăắằẳẵặóòỏõọôốồổỗộơớờởỡợéèẻẽẹêếềểễệúùủũụưứừửữựíìỉĩịýỳỷỹỵđABCDEFGHIJKLMNOPQRSTUVWXYZÁÀẢÃẠÂẤẦẨẪẬĂẮẰẲẴẶÓÒỎÕỌÔỐỒỔỖỘƠỚỜỞỠỢÉÈẺẼẸÊẾỀỂỄỆÚÙỦŨỤƯỨỪỬỮỰÍÌỈĨỊÝỲỶỸỴĐ\")\n",
    "letters2=list(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "typo={\"ă\":\"aw\",\"â\":\"aa\",\"á\":\"as\",\"à\":\"af\",\"ả\":\"ar\",\"ã\":\"ax\",\"ạ\":\"aj\",\"ắ\":\"aws\",\"ổ\":\"oor\",\"ỗ\":\"oox\",\"ộ\":\"ooj\",\"ơ\":\"ow\",\n",
    "\"ằ\":\"awf\",\"ẳ\":\"awr\",\"ẵ\":\"awx\",\"ặ\":\"awj\",\"ó\":\"os\",\"ò\":\"of\",\"ỏ\":\"or\",\"õ\":\"ox\",\"ọ\":\"oj\",\"ô\":\"oo\",\"ố\":\"oos\",\"ồ\":\"oof\",\n",
    "\"ớ\":\"ows\",\"ờ\":\"owf\",\"ở\":\"owr\",\"ỡ\":\"owx\",\"ợ\":\"owj\",\"é\":\"es\",\"è\":\"ef\",\"ẻ\":\"er\",\"ẽ\":\"ex\",\"ẹ\":\"ej\",\"ê\":\"ee\",\"ế\":\"ees\",\"ề\":\"eef\",\n",
    "\"ể\":\"eer\",\"ễ\":\"eex\",\"ệ\":\"eej\",\"ú\":\"us\",\"ù\":\"uf\",\"ủ\":\"ur\",\"ũ\":\"ux\",\"ụ\":\"uj\",\"ư\":\"uw\",\"ứ\":\"uws\",\"ừ\":\"uwf\",\"ử\":\"uwr\",\"ữ\":\"uwx\",\n",
    "\"ự\":\"uwj\",\"í\":\"is\",\"ì\":\"if\",\"ỉ\":\"ir\",\"ị\":\"ij\",\"ĩ\":\"ix\",\"ý\":\"ys\",\"ỳ\":\"yf\",\"ỷ\":\"yr\",\"ỵ\":\"yj\",\"đ\":\"dd\",\n",
    "\"Ă\":\"Aw\",\"Â\":\"Aa\",\"Á\":\"As\",\"À\":\"Af\",\"Ả\":\"Ar\",\"Ã\":\"Ax\",\"Ạ\":\"Aj\",\"Ắ\":\"Aws\",\"Ổ\":\"Oor\",\"Ỗ\":\"Oox\",\"Ộ\":\"Ooj\",\"Ơ\":\"Ow\",\n",
    "\"Ằ\":\"AWF\",\"Ẳ\":\"Awr\",\"Ẵ\":\"Awx\",\"Ặ\":\"Awj\",\"Ó\":\"Os\",\"Ò\":\"Of\",\"Ỏ\":\"Or\",\"Õ\":\"Ox\",\"Ọ\":\"Oj\",\"Ô\":\"Oo\",\"Ố\":\"Oos\",\"Ồ\":\"Oof\",\n",
    "\"Ớ\":\"Ows\",\"Ờ\":\"Owf\",\"Ở\":\"Owr\",\"Ỡ\":\"Owx\",\"Ợ\":\"Owj\",\"É\":\"Es\",\"È\":\"Ef\",\"Ẻ\":\"Er\",\"Ẽ\":\"Ex\",\"Ẹ\":\"Ej\",\"Ê\":\"Ee\",\"Ế\":\"Ees\",\"Ề\":\"Eef\",\n",
    "\"Ể\":\"Eer\",\"Ễ\":\"Eex\",\"Ệ\":\"Eej\",\"Ú\":\"Us\",\"Ù\":\"Uf\",\"Ủ\":\"Ur\",\"Ũ\":\"Ux\",\"Ụ\":\"Uj\",\"Ư\":\"Uw\",\"Ứ\":\"Uws\",\"Ừ\":\"Uwf\",\"Ử\":\"Uwr\",\"Ữ\":\"Uwx\",\n",
    "\"Ự\":\"Uwj\",\"Í\":\"Is\",\"Ì\":\"If\",\"Ỉ\":\"Ir\",\"Ị\":\"Ij\",\"Ĩ\":\"Ix\",\"Ý\":\"Ys\",\"Ỳ\":\"Yf\",\"Ỷ\":\"Yr\",\"Ỵ\":\"Yj\",\"Đ\":\"Dd\"}\n",
    "region={\"ẻ\":\"ẽ\",\"ẽ\":\"ẻ\",\"ũ\":\"ủ\",\"ủ\":\"ũ\",\"ã\":\"ả\",\"ả\":\"ã\",\"ỏ\":\"õ\",\"õ\":\"ỏ\",\"i\":\"j\"}\n",
    "region2={\"s\":\"x\",\"l\":\"n\",\"n\":\"l\",\"x\":\"s\",\"d\":\"gi\",\"S\":\"X\",\"L\":\"N\",\"N\":\"L\",\"X\":\"S\",\"Gi\":\"D\",\"D\":\"Gi\"}\n",
    "vowel=list(\"aeiouyáàảãạâấầẩẫậăắằẳẵặóòỏõọôốồổỗộơớờởỡợéèẻẽẹêếềểễệúùủũụưứừửữựíìỉĩịýỳỷỹỵ\")\n",
    "acronym={\"không\":\"ko\",\" anh\":\" a\",\"em\":\"e\",\"biết\":\"bít\",\"giờ\":\"h\",\"gì\":\"j\",\"muốn\":\"mún\",\"học\":\"hok\",\"yêu\":\"iu\",\n",
    "         \"chồng\":\"ck\",\"vợ\":\"vk\",\" ông\":\" ô\",\"được\":\"đc\",\"tôi\":\"t\",\n",
    "         \"Không\":\"Ko\",\" Anh\":\" A\",\"Em\":\"E\",\"Biết\":\"Bít\",\"Giờ\":\"H\",\"Gì\":\"J\",\"Muốn\":\"Mún\",\"Học\":\"Hok\",\"Yêu\":\"Iu\",\n",
    "         \"Chồng\":\"Ck\",\"Vợ\":\"Vk\",\" Ông\":\" Ô\",\"Được\":\"Đc\",\"Tôi\":\"T\",}\n",
    "teen={\"ch\":\"ck\",\"ph\":\"f\",\"th\":\"tk\",\"nh\":\"nk\",\n",
    "      \"Ch\":\"Ck\",\"Ph\":\"F\",\"Th\":\"Tk\",\"Nh\":\"Nk\"}\n",
    "def teen_code(sentence,pivot):\n",
    "    random = np.random.uniform(0,1,1)[0]\n",
    "    new_sentence=str(sentence)\n",
    "    if random>pivot:\n",
    "        for word in acronym.keys():\n",
    "            if re.search(word, new_sentence):\n",
    "                random2 = np.random.uniform(0,1,1)[0]\n",
    "                if random2 <0.5:\n",
    "                    new_sentence=new_sentence.replace(word,acronym[word])\n",
    "        for word in teen.keys(): \n",
    "            if re.search(word, new_sentence):\n",
    "                random3 = np.random.uniform(0,1,1)[0]\n",
    "                if random3 <0.05:\n",
    "                    new_sentence=new_sentence.replace(word,teen[word])        \n",
    "        return new_sentence\n",
    "    else:\n",
    "        return sentence\n",
    "    \n",
    "\n",
    "def add_noise(sentence, pivot1,pivot2):\n",
    "    sentence=teen_code(sentence,0.5)\n",
    "    noisy_sentence = \"\"\n",
    "    i = 0\n",
    "    while i < len(sentence):\n",
    "        if sentence[i] not in letters:\n",
    "            noisy_sentence+=sentence[i]\n",
    "        else: \n",
    "            random = np.random.uniform(0,1,1)[0]   \n",
    "            if random < pivot1:\n",
    "                noisy_sentence+=(sentence[i])\n",
    "            elif random<pivot2:\n",
    "                if sentence[i] in typo.keys() and sentence[i] in region.keys():\n",
    "                    random2=np.random.uniform(0,1,1)[0]\n",
    "                    if random2<=0.4:\n",
    "                        noisy_sentence+=typo[sentence[i]]\n",
    "                    elif random2<0.8:\n",
    "                        noisy_sentence+=region[sentence[i]]\n",
    "                    elif random2<0.95 :\n",
    "                        noisy_sentence+=unidecode(sentence[i])\n",
    "                    else:\n",
    "                        noisy_sentence+=sentence[i]\n",
    "                elif sentence[i] in typo.keys():\n",
    "                    random3=np.random.uniform(0,1,1)[0]\n",
    "                    if random3<=0.6:\n",
    "                        noisy_sentence+=typo[sentence[i]]\n",
    "                    elif random3<0.9 :\n",
    "                        noisy_sentence+=unidecode(sentence[i])                        \n",
    "                    else:\n",
    "                        noisy_sentence+=sentence[i]\n",
    "                elif sentence[i] in region.keys():\n",
    "                    random4=np.random.uniform(0,1,1)[0]\n",
    "                    if random4<=0.6:\n",
    "                        noisy_sentence+=region[sentence[i]]\n",
    "                    elif random4<0.85 :\n",
    "                        noisy_sentence+=unidecode(sentence[i])                        \n",
    "                    else:\n",
    "                        noisy_sentence+=sentence[i]\n",
    "                elif i<len(sentence)-1 :\n",
    "                    if sentence[i] in region2.keys() and (i==0 or sentence[i-1] not in letters) and sentence[i+1] in vowel:\n",
    "                        random5=np.random.uniform(0,1,1)[0]\n",
    "                        if random5<=0.9:\n",
    "                            noisy_sentence+=region2[sentence[i]]\n",
    "                        else:\n",
    "                            noisy_sentence+=sentence[i]\n",
    "                    else:\n",
    "                        noisy_sentence+=sentence[i]\n",
    "\n",
    "            else:\n",
    "                new_random = np.random.uniform(0,1,1)[0]\n",
    "                if new_random <=0.33:\n",
    "                    if i == (len(sentence) - 1):\n",
    "                        continue\n",
    "                    else:\n",
    "                        noisy_sentence+=(sentence[i+1])\n",
    "                        noisy_sentence+=(sentence[i])\n",
    "                        i += 1\n",
    "                elif new_random <= 0.66:\n",
    "                    random_letter = np.random.choice(letters2, 1)[0]\n",
    "                    noisy_sentence+=random_letter\n",
    "                else:\n",
    "                    pass\n",
    "      \n",
    "        i += 1\n",
    "    return noisy_sentence\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wfWD5D-DeEXW"
   },
   "outputs": [],
   "source": [
    "def extract_phrases(text):\n",
    "    return re.findall(r'\\w[\\w ]+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "J9Oas0TPeLXb",
    "outputId": "0b7f3d06-c1f0-4f7b-badd-e7698d5fc1b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2727033\n",
      "['gây khó khăn cho các ngân hàng', 'Tuy nhiên', 'theo một số ngân hàng thương mại', 'có rất ít các trường hợp khách rút tiền trước hạn', 'Do vậy', 'hiệu quả của quyết định này chưa thấy đâu', 'nhưng trước mắt đã gây cho người gửi tiền tâm lý', 'gửi tiền vào ngân hàng thì dễ', 'rút ra thì khó', 'Điều này hạn chế rất nhiều những nỗ lực huy động vốn của các ngân hàng']\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "phrases = itertools.chain.from_iterable(extract_phrases(text) for text in training_data)\n",
    "phrases = [p.strip() for p in phrases if len(p.split()) > 1]\n",
    "\n",
    "print(len(phrases))\n",
    "print(phrases[-10:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "zdyNMyEZecv2",
    "outputId": "436dde82-8a98-4546-b75f-40be1ec6f112"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2727033 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  from ipykernel import kernelapp as app\n",
      "100%|██████████| 2727033/2727033 [00:33<00:00, 82413.94it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import itertools\n",
    "from nltk import ngrams\n",
    "import string\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def gen_ngrams(words, n=5):\n",
    "    return ngrams(words.split(), n)\n",
    "    \n",
    "list_ngrams = []\n",
    "for p in tqdm(phrases):\n",
    "  if not re.match(alphabet, p.lower()):\n",
    "    continue\n",
    "  for ngr in gen_ngrams(p, NGRAM):\n",
    "    if len(\" \".join(ngr)) < 30:\n",
    "      list_ngrams.append(\" \".join(ngr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "oLdGXkwunTWL",
    "outputId": "a64e060e-752b-49bb-efc1-c28d4c0a6c49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16467058\n"
     ]
    }
   ],
   "source": [
    "del phrases\n",
    "list_ngrams = list((list_ngrams))\n",
    "print(len(list_ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "xfY56WCmh9q4",
    "outputId": "8860f742-04bc-434b-a081-6ac2e7aaf174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\x00', ' ', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'á', 'à', 'ả', 'ã', 'ạ', 'â', 'ấ', 'ầ', 'ẩ', 'ẫ', 'ậ', 'ă', 'ắ', 'ằ', 'ẳ', 'ẵ', 'ặ', 'ó', 'ò', 'ỏ', 'õ', 'ọ', 'ô', 'ố', 'ồ', 'ổ', 'ỗ', 'ộ', 'ơ', 'ớ', 'ờ', 'ở', 'ỡ', 'ợ', 'é', 'è', 'ẻ', 'ẽ', 'ẹ', 'ê', 'ế', 'ề', 'ể', 'ễ', 'ệ', 'ú', 'ù', 'ủ', 'ũ', 'ụ', 'ư', 'ứ', 'ừ', 'ử', 'ữ', 'ự', 'í', 'ì', 'ỉ', 'ĩ', 'ị', 'ý', 'ỳ', 'ỷ', 'ỹ', 'ỵ', 'đ', 'Á', 'À', 'Ả', 'Ã', 'Ạ', 'Â', 'Ấ', 'Ầ', 'Ẩ', 'Ẫ', 'Ậ', 'Ă', 'Ắ', 'Ằ', 'Ẳ', 'Ẵ', 'Ặ', 'Ó', 'Ò', 'Ỏ', 'Õ', 'Ọ', 'Ô', 'Ố', 'Ồ', 'Ổ', 'Ỗ', 'Ộ', 'Ơ', 'Ớ', 'Ờ', 'Ở', 'Ỡ', 'Ợ', 'É', 'È', 'Ẻ', 'Ẽ', 'Ẹ', 'Ê', 'Ế', 'Ề', 'Ể', 'Ễ', 'Ệ', 'Ú', 'Ù', 'Ủ', 'Ũ', 'Ụ', 'Ư', 'Ứ', 'Ừ', 'Ử', 'Ữ', 'Ự', 'Í', 'Ì', 'Ỉ', 'Ĩ', 'Ị', 'Ý', 'Ỳ', 'Ỷ', 'Ỹ', 'Ỵ', 'Đ']\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "\n",
    "alphabet = ['\\x00', ' ', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'á', 'à', 'ả', 'ã', 'ạ', 'â', 'ấ', 'ầ', 'ẩ', 'ẫ', 'ậ', 'ă', 'ắ', 'ằ', 'ẳ', 'ẵ', 'ặ', 'ó', 'ò', 'ỏ', 'õ', 'ọ', 'ô', 'ố', 'ồ', 'ổ', 'ỗ', 'ộ', 'ơ', 'ớ', 'ờ', 'ở', 'ỡ', 'ợ', 'é', 'è', 'ẻ', 'ẽ', 'ẹ', 'ê', 'ế', 'ề', 'ể', 'ễ', 'ệ', 'ú', 'ù', 'ủ', 'ũ', 'ụ', 'ư', 'ứ', 'ừ', 'ử', 'ữ', 'ự', 'í', 'ì', 'ỉ', 'ĩ', 'ị', 'ý', 'ỳ', 'ỷ', 'ỹ', 'ỵ', 'đ', 'Á', 'À', 'Ả', 'Ã', 'Ạ', 'Â', 'Ấ', 'Ầ', 'Ẩ', 'Ẫ', 'Ậ', 'Ă', 'Ắ', 'Ằ', 'Ẳ', 'Ẵ', 'Ặ', 'Ó', 'Ò', 'Ỏ', 'Õ', 'Ọ', 'Ô', 'Ố', 'Ồ', 'Ổ', 'Ỗ', 'Ộ', 'Ơ', 'Ớ', 'Ờ', 'Ở', 'Ỡ', 'Ợ', 'É', 'È', 'Ẻ', 'Ẽ', 'Ẹ', 'Ê', 'Ế', 'Ề', 'Ể', 'Ễ', 'Ệ', 'Ú', 'Ù', 'Ủ', 'Ũ', 'Ụ', 'Ư', 'Ứ', 'Ừ', 'Ử', 'Ữ', 'Ự', 'Í', 'Ì', 'Ỉ', 'Ĩ', 'Ị', 'Ý', 'Ỳ', 'Ỷ', 'Ỹ', 'Ỵ', 'Đ']\n",
    "print(alphabet)\n",
    "print(len(alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hdYUSow2h_dE"
   },
   "outputs": [],
   "source": [
    "def encoder_data(text, maxlen=MAXLEN):\n",
    "        text = \"\\x00\" + text\n",
    "        x = np.zeros((maxlen, len(alphabet)))\n",
    "        for i, c in enumerate(text[:maxlen]):\n",
    "            x[i, alphabet.index(c)] = 1\n",
    "        if i < maxlen - 1:\n",
    "          for j in range(i+1, maxlen):\n",
    "            x[j, 0] = 1\n",
    "        return x\n",
    "      \n",
    "def decoder_data(x):\n",
    "    x = x.argmax(axis=-1)\n",
    "    return ''.join(alphabet[i] for i in x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "id": "D8PCWfwJCd3a",
    "outputId": "fc15143b-c492-4124-a7f8-0ed708ea286c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 199)\n",
      "\u0000Tôi tên là Võ Thị Kim Nguyệt\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n"
     ]
    }
   ],
   "source": [
    "print(encoder_data(\"Tôi tên là võ thị kim nguyệt\").shape)\n",
    "print(decoder_data(encoder_data(\"Tôi tên là Võ Thị Kim Nguyệt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "tVYTzGwVr9DY",
    "outputId": "15934d0e-7209-4055-97fe-8ca7977b4001"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, TimeDistributed, LSTM, Dense, Bidirectional\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m3bwCnPSsEBL"
   },
   "outputs": [],
   "source": [
    "encoder=LSTM(256,input_shape=(MAXLEN, len(alphabet)), return_sequences=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_hJ1B0rshuF"
   },
   "outputs": [],
   "source": [
    "decoder=Bidirectional(LSTM(256, return_sequences=True, dropout=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QEGAP0kvx_dD"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(encoder)\n",
    "model.add(decoder)\n",
    "model.add(TimeDistributed(Dense(256)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(TimeDistributed(Dense(len(alphabet))))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "colab_type": "code",
    "id": "xcYYVoNdfzjs",
    "outputId": "dc24092d-fa19-478d-9253-f711d6fdacba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 40, 256)           466944    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 40, 512)           1050624   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 40, 256)           131328    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 40, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 40, 199)           51143     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 40, 199)           0         \n",
      "=================================================================\n",
      "Total params: 1,700,039\n",
      "Trainable params: 1,700,039\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c6wpr3lxiHZK"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, valid_data = train_test_split(list_ngrams, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sMYZdVyuUPoG"
   },
   "outputs": [],
   "source": [
    "del list_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_8WAhdlXiPZV"
   },
   "outputs": [],
   "source": [
    "def generate_data(data, batch_size):\n",
    "    cur_index = 0\n",
    "    while True:\n",
    "        \n",
    "        x, y = [], []\n",
    "        for i in range(batch_size):  \n",
    "            y.append(encoder_data(data[cur_index]))\n",
    "            x.append(encoder_data(add_noise(data[cur_index],0.94,0.985)))\n",
    "            cur_index += 1\n",
    "            \n",
    "            if cur_index > len(data)-1:\n",
    "                cur_index = 0\n",
    "        \n",
    "        yield np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wyqr-laHiSm1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "train_generator = generate_data(train_data, batch_size=BATCH_SIZE)\n",
    "validation_generator = generate_data(valid_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "lJ8FvJc1jIkL",
    "outputId": "a50ff9b2-acae-46c7-dab0-62a0d71ba822"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object generate_data at 0x7fd4d18ebf68>\n"
     ]
    }
   ],
   "source": [
    "print(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "id": "kn50tT-jjD4-",
    "outputId": "5b1d608e-b7f6-48ba-ceda-397eb5bd0874"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  2901/205838 [..............................] - ETA: 25:35:15 - loss: 0.4042 - accuracy: 0.9098"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=os.path.join('./spell_{val_acc:.4f}.h5'), save_best_only=True, verbose=1)\n",
    "model.fit_generator(train_generator, steps_per_epoch=len(train_data)//BATCH_SIZE, epochs=10,\n",
    "                    validation_data=validation_generator, validation_steps=len(valid_data)//BATCH_SIZE,\n",
    "                    callbacks=[checkpointer])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NguyetVo_ TrainSpell.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
