{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from gensim.models import KeyedVectors \n",
    "dir_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "word2vec_model_path = os.path.join(dir_path, \"Data/vi/vi.vec\")\n",
    "\n",
    "w2v = KeyedVectors.load_word2vec_format(word2vec_model_path)\n",
    "vocab = w2v.wv.vocab\n",
    "wv = w2v.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(word):\n",
    "    return wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = ['giao_thông', 'bóng_đá', 'tài_chính', 'thị_trường', 'sức_khoẻ', 'thế_giới', 'thể_thao', 'ẩm_thực']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word = ['tai_nạn', 'đường_bộ', 'du_lịch', 'ông', 'đau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_best_topic(list_word, list_topic):\n",
    "    best_score = 0\n",
    "    \n",
    "    for topic in list_topic:\n",
    "        topic_score = 0\n",
    "        for word in list_word:\n",
    "            score = wv.similarity(word, topic)\n",
    "            topic_score += score\n",
    "        \n",
    "        if topic_score > best_score:\n",
    "            best_topic = topic\n",
    "            best_score = topic_score\n",
    "    \n",
    "    return best_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'giao_thông'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_topic(list_word, topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer, ViPosTagger\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_doc(doc):\n",
    "    lines = gensim.utils.simple_preprocess(doc)\n",
    "    lines = ' '.join(lines)\n",
    "    lines = ViTokenizer.tokenize(lines)\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "X_data = pickle.load(open('data/X_data.pkl', 'rb'))\n",
    "y_data = pickle.load(open('data/y_data.pkl', 'rb'))\n",
    "\n",
    "# X_test = pickle.load(open('data/X_test.pkl', 'rb'))\n",
    "# y_test = pickle.load(open('data/y_test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level - we choose max number of words equal to 30000 except all words (100k+ words)\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', max_features=30000)\n",
    "tfidf_vect.fit(X_data) # learn vocabulary and idf from training set\n",
    "X_data_tfidf =  tfidf_vect.transform(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=300, n_iter=5,\n",
       "       random_state=42, tol=0.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=300, random_state=42)\n",
    "svd.fit(X_data_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_tfidf_svd = svd.transform(X_data_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import KeyedVectors \n",
    "# import os \n",
    "# dir_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "# word2vec_model_path = os.path.join(dir_path, \"Data/vi/vi.vec\")\n",
    "\n",
    "# w2v = KeyedVectors.load_word2vec_format(word2vec_model_path)\n",
    "# vocab = w2v.wv.vocab\n",
    "# wv = w2v.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_word2vec_data(X):\n",
    "#     word2vec_data = []\n",
    "#     for x in X:\n",
    "#         sentence = []\n",
    "#         for word in x.split(\" \"):\n",
    "#             if word in vocab:\n",
    "# #                 print(word)\n",
    "#                 sentence.append(wv[word])\n",
    "\n",
    "#         word2vec_data.append(sentence)\n",
    "# #         break\n",
    "#     return word2vec_data\n",
    "\n",
    "# X_data_w2v = get_word2vec_data(X_data)\n",
    "# # X_test_w2v = get_word2vec_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "y_data_n = encoder.fit_transform(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chinh tri Xa hoi', 'Doi song', 'Khoa hoc', 'Kinh doanh',\n",
       "       'Phap luat', 'Suc khoe', 'The gioi', 'The thao', 'Van hoa',\n",
       "       'Vi tinh'], dtype='<U16')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, X_data, y_data, X_test=None, y_test=None, is_neuralnet=False, n_epochs=3):       \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.1, random_state=42)\n",
    "    \n",
    "    if is_neuralnet:\n",
    "        classifier.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=n_epochs, batch_size=512)\n",
    "        \n",
    "        val_predictions = classifier.predict(X_val)\n",
    "        test_predictions = classifier.predict(X_test)\n",
    "        val_predictions = val_predictions.argmax(axis=-1)\n",
    "#         test_predictions = test_predictions.argmax(axis=-1)\n",
    "    else:\n",
    "        classifier.fit(X_train, y_train)\n",
    "    \n",
    "        train_predictions = classifier.predict(X_train)\n",
    "        val_predictions = classifier.predict(X_val)\n",
    "#         test_predictions = classifier.predict(X_test)\n",
    "        \n",
    "    print(\"Validation accuracy: \", metrics.accuracy_score(val_predictions, y_val))\n",
    "#     print(\"Test accuracy: \", metrics.accuracy_score(test_predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.8690758293838863\n"
     ]
    }
   ],
   "source": [
    "model = naive_bayes.MultinomialNB()\n",
    "train_model(model, X_data_tfidf, y_data, is_neuralnet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc = '''Tiếp đón ĐT Việt Nam trên sân nhà ở bán kết lượt đi AFF Cup 2018, những sai lầm nơi hàng thủ đã khiến ĐT Philippines nhận thất bại cay đắng 1-2. Sau trận, một số cầu thủ liên tục đăng đàn thể hiện sự tiếc nuối với kết quả này, thậm chí tuyên bố đội nhà xứng đáng giành chiến thắng hơn. \n",
    "\n",
    "Philippines thua Việt Nam: Nội bộ lục đục, báo châu Á khó tin phép màu - 1\n",
    "\n",
    "Patrick Reichelt chỉ trích thái độ thi đấu thiếu quyết tâm của các đồng đội\n",
    "\n",
    "Tuy nhiên khá bất ngờ khi Patrick Reichelt - tác giả bàn gỡ 1-1 lại lên tiếng chỉ trích thái độ thi đấu của các đồng đội giữa thời điểm nhạy cảm. Phản ứng này khiến dư luận nghi ngờ về tình trạng lục đục nội bộ ở Philippines.\n",
    "\n",
    "\"Các cầu thủ chỉ chơi với 80-90% phong độ, điều đó không đủ giúp Philippines chiến thắng. Tôi không hề muốn dừng bước trong lần thứ 3 lọt vào bán kết AFF Cup nhưng nếu toàn đội thi đấu hết mình, tôi sẽ không cảm thấy hối tiếc dù thất bại. Philippines đã có sự chuẩn bị rất tốt, vấn đề nằm ở thái độ thi đấu\", trích lời Reichelt trên Fox Sport Asia.\n",
    "\n",
    "Trong khi đó, chuyên gia bóng đá Đông Nam Á nổi tiếng Gabriel Tan cũng phân tích khá chi tiết những điểm mạnh, điểm yếu của Philppines ở bài viết: \"AFF Cup: Philippines vẫn còn cơ hội sống sót hay Việt Nam đã đặt một chân vào chung kết?\".\n",
    "\n",
    "\"Philippines phần nào tái hiện được tinh thần và lối chơi từng giúp họ cầm hòa ĐKVĐ Thái Lan 1-1 ở vòng bảng. Thầy trò Sven-Goran Eriksson cũng gây ra nhiều khó khăn cho Việt Nam suốt 90 phút, thậm chí trở thành đội đầu tiên chọc thủng lưới Đặng Văn Lâm ở AFF Cup 2018\".\n",
    "\n",
    "Tuy nhiên, Gabriel Tan lại bỏ ngỏ khả năng thầy trò Eriksson lội ngược dòng khi hành quân tới Hà Nội vào ngày 6/12 tới và chỉ gợi lại kỉ niệm đẹp tại SVĐ Mỹ Đình 8 năm trước - thời điểm Philippines đánh bại Việt Nam 2-0:\n",
    "\n",
    "\"Philippines có thể lội ngược dòng? Không có gì đảm bảo cả. Việt Nam vẫn còn nhiều phương án chiến thuật, nhân sự cho khả năng tấn công biên, trong khi The Azkals chỉ còn 18 cầu thủ. Tới Hà Nội, HLV Eriksson chỉ biết hy vọng các học trò thể hiện tinh thần quyết tâm như trận hòa Thái Lan và tái hiện phép màu Hà Nội cách đây 8 năm\".\n",
    "\n",
    "Philippines thua Việt Nam: Nội bộ lục đục, báo châu Á khó tin phép màu - 2\n",
    "\"Phép màu Hà Nội 2010\" là yếu tố để giới chuyên môn lẫn các cầu thủ Philippines bấu víu ở trận bán kết lượt về\n",
    "\n",
    "Về màn trình diễn của ĐT Việt Nam, Gabriel Tan đánh giá rất cao HLV Park Hang Seo với những điều chỉnh chiến thuật, nhân sự cực kì táo bạo, nhạy bén: \n",
    "\n",
    "\"Chiến thắng của Việt Nam ấn tượng hơn cả bởi HLV Park Hang Seo thậm chí chưa tung ra Văn Quyết, Xuân Trường, trong khi Công Phượng chỉ vào sân 10 phút cuối. Thay vào đó, Đức Huy và Hùng Dũng - những cầu thủ mới đá chính ở lượt trận cuối vòng bảng gặp Campuchia - được lựa chọn cho vị trí tiền vệ trung tâm.\n",
    "\n",
    "Nhiều người cho rằng họ vào sân chỉ để giúp Xuân Trường dưỡng sức, tạo điều kiện cho Quang Hải trở về vị trí đá cánh sở trường, nhưng chiến lược gia người Hàn Quốc lại nghĩ khác. Ông không e ngại đặt niềm tin vào những cầu thủ trẻ. Mặt khác, hàng thủ với bộ ba hậu vệ, Đặng Văn Lâm và đôi cánh Trọng Hoàng - Văn Hậu tiếp tục cho thấy sự ăn ý đáng kinh ngạc\".\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc = preprocessing_doc(test_doc)\n",
    "# test_vec = get_word2vec_data([test_doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 30000)\n"
     ]
    }
   ],
   "source": [
    "test_doc_tfidf = tfidf_vect.transform([test_doc])\n",
    "print(np.shape(test_doc_tfidf))\n",
    "test_doc_svd = svd.transform(test_doc_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The thao'], dtype='<U16')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_doc_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
